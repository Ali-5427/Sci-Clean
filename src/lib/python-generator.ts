import type { ProcessedCsvData, ConfirmedTypes, DataType } from './types';

function getPandasTypeConversion(column: string, type: DataType): string {
    const safeCol = column.includes("'") ? `"${column}"` : `'${column}'`;
    switch (type) {
        case 'NUMERIC':
            return `df[${safeCol}] = pd.to_numeric(df[${safeCol}], errors='coerce')`;
        case 'TEXT':
            return `df[${safeCol}] = df[${safeCol}].astype(str).replace('nan', np.nan)`;
        case 'DATE':
            // This is a generic date parser. For production, more robust format detection would be needed.
            return `df[${safeCol}] = pd.to_datetime(df[${safeCol}], errors='coerce')`;
        case 'CATEGORICAL':
            return `df[${safeCol}] = df[${safeCol}].astype('category')`;
        default:
            return `# No conversion rule for type: ${type}`;
    }
}

export function generatePythonScript(
    processedData: ProcessedCsvData,
    confirmedTypes: ConfirmedTypes
): string {
    const now = new Date();
    const typeConversionSteps = Object.entries(confirmedTypes)
        .map(([columnName, { type }]) => {
            const conversionCode = getPandasTypeConversion(columnName, type);
            return `
# Convert '${columnName}' to ${type}
print("Converting '${columnName}' to ${type}...")
${conversionCode}
`;
        })
        .join('');

    return `"""
CLEANED DATA GENERATION SCRIPT
Generated by Sci-Clean Studio
Date: ${now.toISOString()}
Original File: ${processedData.fileName}
Original Hash (SHA-256): ${processedData.fileHash}

This script replicates the exact cleaning steps performed in Sci-Clean Studio.
Run this script to regenerate the cleaned data from the original file.
"""

import pandas as pd
import numpy as np

# --- CONFIGURATION ---
INPUT_FILE = '${processedData.fileName}'
OUTPUT_FILE = 'cleaned_${processedData.fileName}'

# --- LOAD DATA ---
try:
    print(f"Loading data from {INPUT_FILE}...")
    df = pd.read_csv(INPUT_FILE)
    print(f"Loaded: {len(df)} rows × {len(df.columns)} columns")
except FileNotFoundError:
    print(f"ERROR: Input file not found at '{INPUT_FILE}'. Please ensure the script is in the same directory as the data file.")
    exit()

# --- STEP 1: DATA TYPE CONVERSIONS ---
print("\\n--- Step 1: Converting data types ---")
${typeConversionSteps}
print("Data type conversion complete.")

# --- STEP 2: HANDLE MISSING DATA (Placeholder) ---
# NOTE: This MVP version does not include imputation.
# The following section is a placeholder for future functionality.
print("\\n--- Step 2: Handling missing values (No imputation in this version) ---")
missing_before = df.isnull().sum().sum()
print(f"Total missing values before imputation: {missing_before}")
# Example imputation (currently disabled):
# if df['income'].isnull().sum() > 0:
#     print(f"Imputing {df['income'].isnull().sum()} missing values in 'income' with mean...")
#     df['income'] = df['income'].fillna(df['income'].mean())


# --- STEP 3: SAVE CLEANED DATA ---
print("\\n--- Step 3: Saving cleaned data ---")
df.to_csv(OUTPUT_FILE, index=False)
print(f"✅ Cleaned data saved to: {OUTPUT_FILE}")

# --- FINAL SUMMARY ---
print("\\n--- Summary ---")
print(f"Final shape: {len(df)} rows × {len(df.columns)} columns")
final_missing_values = df.isnull().sum().sum()
print(f"Total missing values in cleaned file: {final_missing_values} cells")
print("Script finished.")
`;
}
