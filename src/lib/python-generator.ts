
import type { ProcessedCsvData, ConfirmedTypes, DataType } from './types';

function getPandasTypeConversion(column: string, type: DataType): string {
    const safeCol = column.includes("'") ? `"${column}"` : `'${column}'`;
    switch (type) {
        case 'NUMERIC':
            return `df[${safeCol}] = pd.to_numeric(df[${safeCol}], errors='coerce')`;
        case 'TEXT':
            return `df[${safeCol}] = df[${safeCol}].astype(str).replace('nan', np.nan)`;
        case 'DATE':
            // This is a generic date parser. For production, more robust format detection would be needed.
            return `df[${safeCol}] = pd.to_datetime(df[${safeCol}], errors='coerce')`;
        case 'CATEGORICAL':
            return `df[${safeCol}] = df[${safeCol}].astype('category')`;
        default:
            return `# No conversion rule for type: ${type}`;
    }
}

export function generatePythonScript(
    processedData: ProcessedCsvData,
    confirmedTypes: ConfirmedTypes
): string {
    const now = new Date();
    const typeConversionSteps = Object.entries(confirmedTypes)
        .map(([columnName, { type }]) => {
            return `df[${JSON.stringify(columnName)}] = pd.to_numeric(df[${JSON.stringify(columnName)}], errors='coerce')`;
        })
        .join('\\n');

    return `"""
CLEANED DATA GENERATION SCRIPT
Generated by Sci-Clean Studio (Research-Grade)
Date: ${now.toISOString()}
Original File: ${processedData.fileName}
Original Hash (SHA-256): ${processedData.fileHash}

This script replicates the exact cleaning steps performed in Sci-Clean Studio.
Run this script to regenerate the cleaned data from the original file.
"""

import pandas as pd
import numpy as np
from scipy import stats

# --- CONFIGURATION ---
INPUT_FILE = '${processedData.fileName}'
OUTPUT_FILE = 'cleaned_${processedData.fileName}'

# --- LOAD DATA ---
try:
    print(f"Loading data from {INPUT_FILE}...")
    df = pd.read_csv(INPUT_FILE)
    print(f"Loaded: {len(df)} rows × {len(df.columns)} columns")
except FileNotFoundError:
    print(f"ERROR: Input file not found at '{INPUT_FILE}'. Please ensure the script is in the same directory as the data file.")
    exit()

# --- STEP 1: DATA TYPE CONVERSIONS ---
print("\\n--- Step 1: Converting data types ---")
${Object.entries(confirmedTypes)
        .map(([columnName, { type }]) => {
            const conversionCode = getPandasTypeConversion(columnName, type);
            return `
# Convert '${columnName}' to ${type}
print("Converting '${columnName}' to ${type}...")
${conversionCode}
`;
        })
        .join('')}
print("Data type conversion complete.")

# --- STEP 2: SCIENTIFIC IMPUTATION ---
print("\\n--- Step 2: Imputation (Forward Fill) ---")
missing_before = df.isnull().sum().sum()
# Forward-fill propagates the last valid observation forward.
df.fillna(method='ffill', inplace=True)
# Fill any remaining NaNs at the beginning of the file with 0
df.fillna(0, inplace=True)
imputed_count = missing_before - df.isnull().sum().sum()
print(f"Imputed {imputed_count} missing values using Forward Fill strategy.")


# --- STEP 3: ANOMALY DETECTION (Z-Score) ---
print("\\n--- Step 3: Flagging Anomalies ---")
# This step identifies and flags rows with potential anomalies based on Z-score.
# It adds a new column 'is_anomaly' without removing data.
df['is_anomaly'] = False
numeric_cols = df.select_dtypes(include=np.number).columns
for col in numeric_cols:
    # Ensure column has variance before calculating Z-scores
    if df[col].std() > 0:
        z_scores = np.abs(stats.zscore(df[col]))
        anomalies = np.where(z_scores > 3)[0]
        if len(anomalies) > 0:
            print(f"⚠️  Found {len(anomalies)} potential anomalies in '{col}' (Z-Score > 3)")
            df.loc[anomalies, 'is_anomaly'] = True


# --- STEP 4: SAVE CLEANED DATA ---
print("\\n--- Step 4: Saving cleaned data ---")
df.to_csv(OUTPUT_FILE, index=False)
print(f"✅ Cleaned data saved to: {OUTPUT_FILE}")

# --- FINAL SUMMARY ---
print("\\n--- Summary ---")
print(f"Final shape: {len(df)} rows × {len(df.columns)} columns")
final_missing_values = df.isnull().sum().sum()
print(f"Total missing values in cleaned file: {final_missing_values} cells")
print("Script finished.")
`;
}
